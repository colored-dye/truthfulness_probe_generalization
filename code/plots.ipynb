{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separation between true/false statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, AutoTokenizer, AutoConfig,\n",
    "    QuantoConfig\n",
    ")\n",
    "\n",
    "from utils import *\n",
    "\n",
    "# MODEL_PATH = \"/Model/meta-llama/Llama-2-7b-hf\"\n",
    "# MODEL_PATH = \"/Model/meta-llama/Llama-2-7b-chat-hf\"\n",
    "# MODEL_PATH = \"/Model/meta-llama/Llama-2-13b-hf\"\n",
    "# MODEL_PATH = \"/Model/meta-llama/Llama-2-13b-chat-hf\"\n",
    "# MODEL_PATH = \"/Model/meta-llama/Meta-Llama-3.1-8B-hf\"\n",
    "# MODEL_PATH = \"/Model/meta-llama/Meta-Llama-3.1-8B-Instruct-hf\"\n",
    "# MODEL_PATH = \"/Model/meta-llama/Meta-Llama-3.1-70B-hf\"\n",
    "# MODEL_PATH = \"/Model/meta-llama/Meta-Llama-3.1-70B-Instruct-hf\"\n",
    "\n",
    "# MODEL_PATH = \"/Model/mistralai/Mistral-7B-v0.1\"\n",
    "MODEL_PATH = \"/Model/mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "# MODEL_PATH = \"/Model/mistralai/Mistral-Large-Instruct-2407\"\n",
    "\n",
    "model_name = os.path.basename(MODEL_PATH)\n",
    "\n",
    "config = AutoConfig.from_pretrained(MODEL_PATH)\n",
    "# tok = AutoTokenizer.from_pretrained(MODEL_PATH, use_fast=False)\n",
    "# if tok.pad_token is None:\n",
    "#     tok.pad_token = tok.eos_token\n",
    "# tok.padding_side = 'left'\n",
    "\n",
    "# quant_config = QuantoConfig(weights='float8')\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     MODEL_PATH,\n",
    "#     # torch_dtype=torch.bfloat16,\n",
    "#     device_map='auto',\n",
    "#     attn_implementation=\"eager\",\n",
    "#     quantization_config=quant_config\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"data/\"\n",
    "topics = [\n",
    "    \"animal_class\",\n",
    "    \"cities\",\n",
    "    \"facts\",\n",
    "    \"sp_en_trans\",\n",
    "    \"inventors\",\n",
    "    \"element_symb\",\n",
    "]\n",
    "dataset_names = []\n",
    "for t in topics:\n",
    "    dataset_names.append(t)\n",
    "    dataset_names.append(\"neg_\"+t)\n",
    "    dataset_names.append(t+\"_conj\")\n",
    "    dataset_names.append(t+\"_disj\")\n",
    "\n",
    "prompt_option = \"no_prompt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts_dir = f\"activations_and_labels/{model_name}/{prompt_option}\"\n",
    "os.makedirs(acts_dir, exist_ok=True)\n",
    "activations_dict = {}\n",
    "labels_dict = {}\n",
    "for k in dataset_names:\n",
    "    print(k)\n",
    "    task_dir = os.path.join(acts_dir, k)\n",
    "    acts = []\n",
    "    for layer in range(config.num_hidden_layers):\n",
    "        acts.append(np.load(os.path.join(task_dir, f\"acts_{layer}.npy\")))\n",
    "    labels = np.array(pd.read_csv(f\"data/{k}.csv\")['label'].tolist())\n",
    "    activations_dict[k] = np.array(acts)\n",
    "    labels_dict[k] = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "\n",
    "seaborn.set_style('whitegrid')\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "relative_variances_all = 0\n",
    "data_df = {\n",
    "    \"data\": [],\n",
    "    \"index\": [],\n",
    "    \"group\": [],\n",
    "}\n",
    "for k in activations_dict:\n",
    "    activations_by_layer = activations_dict[k]\n",
    "    labels = labels_dict[k]\n",
    "\n",
    "    between_class_variances = []\n",
    "    within_class_variances = []\n",
    "    for layer_nr in range(config.num_hidden_layers):\n",
    "        # Calculate means for each class\n",
    "        false_stmnt_ids = labels == 0\n",
    "        true_stmnt_ids = labels == 1\n",
    "\n",
    "        false_acts = activations_by_layer[layer_nr, false_stmnt_ids]\n",
    "        true_acts = activations_by_layer[layer_nr, true_stmnt_ids]\n",
    "\n",
    "        mean_false = false_acts.mean(axis=0)\n",
    "        mean_true = true_acts.mean(axis=0)\n",
    "\n",
    "        # Calculate within-class variance\n",
    "        within_class_variance_false = np.var(false_acts, axis=0).mean()\n",
    "        within_class_variance_true = np.var(true_acts, axis=0).mean()\n",
    "        within_class_variances.append((within_class_variance_false + within_class_variance_true) / 2)\n",
    "\n",
    "        # Calculate between-class variance\n",
    "        overall_mean = activations_by_layer[layer_nr].mean(axis=0)\n",
    "        between_class_variances.append(((mean_false - overall_mean)**2\n",
    "                                        + (mean_true - overall_mean)**2).mean().item() / 2)\n",
    "\n",
    "    relative_variances = np.array(between_class_variances) / np.array(within_class_variances)\n",
    "    # ax = plt.plot(range(len(relative_variances)), relative_variances, label=k)\n",
    "    # plt.annotate(relative_variances.argmax(), xy=(relative_variances.argmax(), relative_variances.max()), c=ax[0].get_color(), fontsize=12)\n",
    "    relative_variances_all += relative_variances\n",
    "\n",
    "    for layer_nr in range(config.num_hidden_layers):\n",
    "        data_df['data'].append(relative_variances[layer_nr])\n",
    "        data_df['index'].append(layer_nr)\n",
    "        data_df['group'].append(k.replace(\"neg_\",\"\").replace(\"_conj\",\"\").replace(\"_disj\",\"\"))\n",
    "        # if \"neg\" in k:\n",
    "        #     data_df['group'].append('neg')\n",
    "        # elif \"conj\" in k:\n",
    "        #     data_df['group'].append('conj')\n",
    "        # elif \"disj\" in k:\n",
    "        #     data_df['group'].append('disj')\n",
    "        # else:\n",
    "        #     data_df['group'].append('affirm')\n",
    "# plt.yscale('log')\n",
    "# plt.legend()\n",
    "# plt.xlabel(\"Layers (starting from 0)\", fontsize=14)\n",
    "# plt.ylabel(\"Ratio\", fontsize=20)\n",
    "# plt.xticks(fontsize=20)\n",
    "# plt.yticks(fontsize=20)\n",
    "# plt.title(model_name.replace(\"-hf\",\"\").replace(\"Meta-\",\"\").replace(\"b\",'B'), fontsize=20)\n",
    "\n",
    "data_df = pd.DataFrame(data_df)\n",
    "draw_df = data_df.reset_index().melt(id_vars=['index', 'group'], var_name='col')\n",
    "# seaborn.lineplot(draw_df, x='index', y='value', hue='group', legend=False)\n",
    "ax = seaborn.lineplot(data_df, x='index', y='data', hue='group', errorbar=('se'))\n",
    "\n",
    "for i, topic in enumerate(topics):\n",
    "    topic_data = data_df.loc[data_df['group'] == topic]\n",
    "    line = [0 for _ in range(config.num_hidden_layers)]\n",
    "    for _, rec in topic_data.iterrows():\n",
    "        line[rec['index']] += rec['data']\n",
    "    line = np.array(line)/4\n",
    "    peak_index = np.argmax(line)\n",
    "    plt.annotate(peak_index, xy=(peak_index, line[peak_index]), c=ax.lines[i].get_color(), fontsize=14)\n",
    "\n",
    "ax.legend_.set_title('')\n",
    "ax.set_xlabel(\"Layer\", fontsize=14)\n",
    "ax.set_ylabel(\"Ratio\", fontsize=14)\n",
    "ax.tick_params(labelsize=14)\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize=14)\n",
    "\n",
    "variance_dir = \"figures_relative_variance/\"\n",
    "os.makedirs(variance_dir, exist_ok=True)\n",
    "figname = os.path.join(variance_dir, f\"{model_name}_{prompt_option}.pdf\")\n",
    "if os.path.exists(figname):\n",
    "    os.remove(figname)\n",
    "plt.tight_layout()\n",
    "plt.savefig(figname)\n",
    "\n",
    "print(relative_variances_all.argmax())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probe performance by layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set_style('whitegrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"results/\"\n",
    "\n",
    "# model_name = \"Mistral-Large-Instruct-2407\"\n",
    "# model_name = \"Meta-Llama-3.1-70B-Instruct-hf\"\n",
    "model_name = \"Meta-Llama-3.1-70B-hf\"\n",
    "# model_name = \"Meta-Llama-3.1-8B-Instruct-hf\"\n",
    "# model_name = \"Llama-2-7b-chat-hf\"\n",
    "\n",
    "n_layers = 80\n",
    "prompt_option = \"no_prompt\"\n",
    "topics = [\n",
    "    \"cities\",\n",
    "    # \"inventors\",\n",
    "    \"sp_en_trans\",\n",
    "    # \"element_symb\",\n",
    "    # \"element_symb_new\",\n",
    "    # \"companies\",\n",
    "    # \"facts\",\n",
    "]\n",
    "results = {}\n",
    "for topic in topics:\n",
    "    result_file = os.path.join(results_dir, f\"{model_name}_{topic}_{prompt_option}.jsonl\")\n",
    "    results_topic = []\n",
    "    with open(result_file) as fp:\n",
    "        for line in fp:\n",
    "            results_topic.append(json.loads(line))\n",
    "    results[topic] = results_topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "for topic in topics:\n",
    "    results_topic = results[topic]\n",
    "    plt.plot([rec['cosine_sim'] for rec in results_topic], label=topic, marker='.')\n",
    "\n",
    "plt.legend()\n",
    "plt.plot([0,n_layers], [0,0], 'k--')\n",
    "plt.xticks(range(0, n_layers, 10))\n",
    "plt.xlabel(\"Layers (starting from 0)\")\n",
    "plt.ylabel(\"Cosine similarity between\\naffirmative/negated truthful direction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_range = [0, n_layers]\n",
    "sep = 10\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(21,4))\n",
    "probe_names = ('lr', 'mlp', 'mm')\n",
    "for i, probe_name in enumerate(probe_names):\n",
    "    for topic in topics:\n",
    "        results_topic = results[topic]\n",
    "        aurocs = []\n",
    "        for rec in results_topic:\n",
    "            for probe in rec['probes']:\n",
    "                if probe['probe'] == probe_name:\n",
    "                    aurocs.append(probe['auroc'])\n",
    "        axes[i].plot(aurocs[layers_range[0]:layers_range[1]], label=topic, marker='.')\n",
    "    axes[i].legend()\n",
    "    axes[i].plot(layers_range, [0.5,0.5], 'k--')\n",
    "    axes[i].set_xticks(range(layers_range[0], layers_range[1]+1, sep))\n",
    "    axes[i].set_xlabel(\"Layers (starting from 0)\")\n",
    "    axes[i].set_ylabel(\"AUROC\")\n",
    "    axes[i].set_title(probe_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_range = [0, n_layers]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(19,4))\n",
    "probe_names = ('lr', 'mlp', 'mm', 'svm')\n",
    "for i, probe_name in enumerate(probe_names):\n",
    "    for topic in topics:\n",
    "        results_topic = results[topic]\n",
    "        accs = []\n",
    "        for rec in results_topic:\n",
    "            for probe in rec['probes']:\n",
    "                if probe['probe'] == probe_name:\n",
    "                    if probe['best_acc'] is not None:\n",
    "                        accs.append(probe['best_acc'])\n",
    "                    else:\n",
    "                        accs.append(probe['acc'])\n",
    "        axes[i].plot(range(layers_range[0], layers_range[1]), accs[layers_range[0]:layers_range[1]], label=topic, marker='.')\n",
    "    axes[i].legend()\n",
    "    axes[i].plot(layers_range, [0.5,0.5], 'k--')\n",
    "    axes[i].set_xticks(range(layers_range[0], layers_range[1]+1, 10))\n",
    "    axes[i].set_xlabel(\"Layers (starting from 0)\")\n",
    "    axes[i].set_ylabel(\"Best acc\")\n",
    "    axes[i].set_title(probe_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalization from affirmative statements to negative statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "model_names = (\n",
    "    \"Llama-2-7b-hf\",\n",
    "    \"Llama-2-7b-chat-hf\",\n",
    "    \"Llama-2-13b-hf\",\n",
    "    \"Llama-2-13b-chat-hf\",\n",
    "    \"Meta-Llama-3.1-8B-hf\",\n",
    "    \"Meta-Llama-3.1-8B-Instruct-hf\",\n",
    "    \"Meta-Llama-3.1-70B-hf\",\n",
    "    \"Meta-Llama-3.1-70B-Instruct-hf\",\n",
    ")\n",
    "# layer_indices = (\n",
    "#     13,\n",
    "#     37,\n",
    "# )\n",
    "\n",
    "prompt_option = \"no_prompt\"\n",
    "topics = (\n",
    "    \"animal_class\",\n",
    "    \"cities\",\n",
    "    \"inventors\",\n",
    "    \"facts\",\n",
    "    \"element_symb\",\n",
    "    # \"companies\",\n",
    "    \"sp_en_trans\",\n",
    ")\n",
    "probe_names = (\"lr\", \"mlp\", \"svm\", \"mm\")\n",
    "\n",
    "aurocs = []\n",
    "# for probe in probe_names:\n",
    "#     aurocs[probe] = {}\n",
    "#     for model_name, layer_index in zip(model_names, layer_indices):\n",
    "#         aurocs_model = {}\n",
    "#         for topic in topics:\n",
    "#             results = []\n",
    "#             with open(os.path.join(\"results/\", f\"{model_name}_{topic}_{prompt_option}.jsonl\")) as fp:\n",
    "#                 for line in fp:\n",
    "#                     results.append(json.loads(line))\n",
    "#             results = results[layer_index]\n",
    "#             aurocs_topic = []\n",
    "#             for rec in results['probes']:\n",
    "#                 if rec['probe'] == probe:\n",
    "#                     aurocs_topic = rec['auroc']\n",
    "#             aurocs_model[topic] = aurocs_topic\n",
    "#         aurocs[probe][model_name.strip(\"-hf\")] = aurocs_model\n",
    "\n",
    "results_dir = \"neg_generalization_results/\"\n",
    "seeds = [0,1,2]\n",
    "for seed in seeds:\n",
    "    aurocs_seed = {}\n",
    "    for probe in probe_names:\n",
    "        aurocs_seed[probe] = {}\n",
    "        probe_results = pd.read_csv(os.path.join(results_dir, f\"seed={seed}/{probe}.csv\"))\n",
    "        for _, rec in probe_results.iterrows():\n",
    "            aurocs_model = {}\n",
    "            for topic in topics:\n",
    "                if not np.isnan(rec[topic]):\n",
    "                    aurocs_model[topic] = rec[topic]\n",
    "            model_name = rec['model']\n",
    "            if model_name in model_names:\n",
    "                # m = model_name.replace(\"-hf\",\"\").replace(\"Meta-\",\"\").replace('b','B').replace(\"-chat\",\"-Chat\")\n",
    "                # m = m.replace(\"Llama\", \"L\").replace(\"Chat\", \"C\").replace(\"Instruct\", \"I\")\n",
    "                m = \"M\" + str(model_names.index(model_name))\n",
    "                aurocs_seed[probe][m] = aurocs_model\n",
    "    aurocs.append(aurocs_seed)\n",
    "\n",
    "# aurocs_avg = {}\n",
    "# for auroc_seed in aurocs:\n",
    "#     for probe, auroc_model in auroc_seed.items():\n",
    "#         aurocs_avg[probe] = {}\n",
    "#         for model_name, auroc_topic in auroc_model.items():\n",
    "#             aurocs_avg[probe][model_name] = {}\n",
    "#             for topic, auroc in auroc_topic.items():\n",
    "#                 if topic not in aurocs_avg[probe][model_name]:\n",
    "#                     aurocs_avg[probe][model_name][topic] = 0\n",
    "#                 aurocs_avg[probe][model_name][topic] += auroc\n",
    "# for probe, auroc_model in aurocs_avg.items():\n",
    "#     for model_name, auroc_topic in auroc_model.items():\n",
    "#         for topic, auroc in auroc_topic.items():\n",
    "#             # x = np.round(aurocs_avg[probe][model_name][topic], 2)\n",
    "#             # if x == 0.0:\n",
    "#             #     x = 0\n",
    "#             # elif x == 1.0:\n",
    "#             #     x = 1\n",
    "#             x = np.round(aurocs_avg[probe][model_name][topic]*100, 0).astype(np.int32)\n",
    "#             aurocs_avg[probe][model_name][topic] = x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils._pytree as pytree_utils\n",
    "\n",
    "aurocs_avg = pytree_utils.tree_map(lambda x, y, z: round((x + y + z)/3*100), aurocs[0], aurocs[1], aurocs[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE_SIZE = 16\n",
    "TICK_LABEL_SIZE = 14\n",
    "ANNOT_SIZE = 18\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(7, 10), gridspec_kw={'hspace': 0.02, 'wspace': 0.01})\n",
    "cbar_ax = fig.add_axes([.93, 0.122, .02, .75])\n",
    "\n",
    "for i, probe in enumerate(probe_names):\n",
    "    ax = seaborn.heatmap(\n",
    "        pd.DataFrame(aurocs_avg[probe]).T,\n",
    "        annot=True,\n",
    "        annot_kws={\"fontsize\":ANNOT_SIZE},\n",
    "        vmin=0,\n",
    "        vmax=100,\n",
    "        square=True,\n",
    "        cmap='coolwarm',\n",
    "        fmt='d',\n",
    "        ax=axes[i//2][i%2],\n",
    "        cbar=(i==0),\n",
    "        cbar_ax=cbar_ax,\n",
    "    )\n",
    "    ax.set_title(probe.upper(), fontsize=TITLE_SIZE)\n",
    "    if i == 2:\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), fontsize=TICK_LABEL_SIZE, rotation=20, ha='right')\n",
    "        ax.set_yticklabels(\n",
    "            ax.get_yticklabels(),\n",
    "            fontsize=TICK_LABEL_SIZE,\n",
    "        )\n",
    "        ax.tick_params(left=True, bottom=True)\n",
    "    else:\n",
    "        # ax.set_xlabel(None)\n",
    "        # ax.set_ylabel(None)\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.tick_params(left=False, bottom=False)\n",
    "cbar_ax.tick_params(labelsize=TICK_LABEL_SIZE)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.01)\n",
    "\n",
    "# figname = \"figures_heatmap/neg_generalization.pdf\"\n",
    "# if os.path.exists(figname):\n",
    "#     os.remove(figname)\n",
    "# plt.savefig(figname, format='pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE_SIZE = 12\n",
    "TICK_LABEL_SIZE = 12\n",
    "ANNOT_SIZE = 10\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(13, 1.6), gridspec_kw={'wspace': 0.01})\n",
    "cbar_ax = fig.add_axes([.91, 0.15, .01, .7])\n",
    "\n",
    "for i, probe in enumerate(probe_names):\n",
    "    ax = seaborn.heatmap(\n",
    "        pd.DataFrame(aurocs_avg[probe]),\n",
    "        annot=True,\n",
    "        annot_kws={\"fontsize\":ANNOT_SIZE},\n",
    "        vmin=0,\n",
    "        vmax=100,\n",
    "        # square=True,\n",
    "        cmap='coolwarm',\n",
    "        fmt='d',\n",
    "        ax=axes[i],\n",
    "        cbar=(i==0),\n",
    "        cbar_ax=cbar_ax,\n",
    "    )\n",
    "    ax.set_title(probe.upper(), fontsize=TITLE_SIZE)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=TICK_LABEL_SIZE, ha='center')\n",
    "    if i == 0:\n",
    "        ax.set_yticklabels(\n",
    "            ax.get_yticklabels(),\n",
    "            fontsize=TICK_LABEL_SIZE,\n",
    "        )\n",
    "        ax.tick_params(left=True, bottom=True)\n",
    "    else:\n",
    "        ax.set_yticklabels([])\n",
    "        ax.tick_params(left=False)\n",
    "cbar_ax.tick_params(labelsize=TICK_LABEL_SIZE)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.01)\n",
    "\n",
    "figname = \"figures_heatmap/neg_generalization.pdf\"\n",
    "if os.path.exists(figname):\n",
    "    os.remove(figname)\n",
    "plt.savefig(figname, format='pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generalization_num = [0, 0, 4, 4, 4, 4, 5, 6]\n",
    "models = [f\"M{i}\" for i in range(8)]\n",
    "from math import pi\n",
    " \n",
    "# Set data\n",
    "df = pd.DataFrame({\n",
    "'model': models,\n",
    "'data': generalization_num,\n",
    "})\n",
    "\n",
    "N = len(models)\n",
    " \n",
    "# We are going to plot the first line of the data frame.\n",
    "# But we need to repeat the first value to close the circular graph:\n",
    "values=generalization_num\n",
    " \n",
    "# What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "# angles += angles[:1]\n",
    " \n",
    "# Initialise the spider plot\n",
    "ax = plt.subplot(111, polar=True)\n",
    " \n",
    "# Draw one axe per variable + add labels\n",
    "plt.xticks(angles, models)\n",
    " \n",
    "# Draw ylabels\n",
    "ax.set_rlabel_position(0)\n",
    "plt.yticks(range(6), range(6), color=\"grey\")\n",
    "plt.ylim(0,6)\n",
    " \n",
    "# Plot data\n",
    "ax.plot(angles, values, linewidth=1, linestyle='solid')\n",
    " \n",
    "# Fill area\n",
    "ax.fill(angles, values, 'b', alpha=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalization to logical conjunction/disjunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "from probes import *\n",
    "from utils import *\n",
    "\n",
    "\n",
    "model_names_layer_indices = {\n",
    "    \"Llama-2-7b-hf\": 12,\n",
    "    \"Llama-2-7b-chat-hf\": 13,\n",
    "    \"Llama-2-13b-hf\": 13,\n",
    "    \"Llama-2-13b-chat-hf\": 13,\n",
    "    \"Meta-Llama-3.1-8B-hf\": 12,\n",
    "    \"Meta-Llama-3.1-8B-Instruct-hf\": 13,\n",
    "    \"Meta-Llama-3.1-70B-hf\": 33,\n",
    "    \"Meta-Llama-3.1-70B-Instruct-hf\": 37,\n",
    "    # \"Mistral-Large-Instruct-2407\": 43,\n",
    "}\n",
    "\n",
    "prompt_option = \"no_prompt\"\n",
    "\n",
    "topics = (\n",
    "    \"animal_class\",\n",
    "    \"cities\",\n",
    "    \"inventors\",\n",
    "    \"facts\",\n",
    "    \"element_symb\",\n",
    "    \"sp_en_trans\",\n",
    ")\n",
    "probe_names = ('lr', 'mlp', 'svm', 'mm')\n",
    "logical_transformation = \"conj\" # conj / disj\n",
    "\n",
    "aurocs = []\n",
    "for seed in (0,1,2):\n",
    "    print(f\"seed={seed}\")\n",
    "    aurocs_seed = {}\n",
    "    for probe_name in probe_names:\n",
    "        print(f\"  probe={probe_name}\")\n",
    "        aurocs_seed[probe_name] = {}\n",
    "        for model_name, layer_index in model_names_layer_indices.items():\n",
    "            print(f\"    model={model_name}\")\n",
    "            aurocs_seed[model_name] = {}\n",
    "            activations_dir = f\"activations_and_labels/{model_name}/{prompt_option}\"\n",
    "            probes_dir = f\"probes/{model_name}/seed={seed}\"\n",
    "            probe = joblib.load(os.path.join(probes_dir, f\"{probe_name}.joblib\"))\n",
    "            aurocs_seed[probe_name][model_name] = {}\n",
    "            for topic in topics:\n",
    "                print(f\"      topic={topic}\")\n",
    "                aurocs_seed[probe_name][model_name][topic] = {}\n",
    "                test_topic = topic + \"_\" + logical_transformation\n",
    "                if logical_transformation == \"disj\" and topic != \"facts\":\n",
    "                    test_topic += \"_new\"\n",
    "                test_activations = np.load(f\"{activations_dir}/{test_topic}/acts_{layer_index}.npy\")\n",
    "                test_labels = pd.read_csv(f\"data/{test_topic}.csv\")['label']\n",
    "                test_labels = np.array(test_labels.tolist())\n",
    "            \n",
    "                pos_label_probs = probe.predict_proba(test_activations)[:, 1]\n",
    "                auroc = roc_auc_score(test_labels, pos_label_probs)\n",
    "                aurocs_seed[probe_name][model_name][topic] = auroc\n",
    "    aurocs.append(aurocs_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils._pytree as pytree_utils\n",
    "\n",
    "def tree_average(trees, scale=1, round_to_int=False):\n",
    "    tree_sum = trees[0]\n",
    "    for tree in trees[1:]:\n",
    "        tree_sum = pytree_utils.tree_map(lambda x, y: x + y, tree_sum, tree)\n",
    "    avg_fn = lambda x: round(x/len(trees)*scale) if round_to_int else x/len(trees)*scale\n",
    "    tree_avg = pytree_utils.tree_map(avg_fn, tree_sum)\n",
    "    return tree_avg\n",
    "\n",
    "aurocs_avg = tree_average(aurocs, scale=100, round_to_int=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aurocs_avg_new = {}\n",
    "for k, d in aurocs_avg.items():\n",
    "    aurocs_avg_new[k] = {}\n",
    "    for m, v in d.items():\n",
    "        aurocs_avg_new[k][m.replace(\"-hf\",\"\").replace(\"Meta-\",\"\").replace('b','B').replace(\"-chat\",\"-Chat\")] = v\n",
    "aurocs_avg = aurocs_avg_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aurocs_avg_single_model = {}\n",
    "target_model = 'Llama-3.1-8B'\n",
    "for probe in probe_names:\n",
    "    aurocs_avg_single_model[probe] = {}\n",
    "    for topic in topics:\n",
    "        aurocs_avg_single_model[probe][topic] = aurocs_avg[probe][target_model][topic]\n",
    "\n",
    "TITLE_SIZE = 20\n",
    "TICK_LABEL_SIZE = 20\n",
    "ANNOT_SIZE = 20\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "cbar_ax = fig.add_axes([.92, .25, .03, .5])\n",
    "ax = seaborn.heatmap(\n",
    "    pd.DataFrame(aurocs_avg_single_model).T,\n",
    "    annot=True,\n",
    "    annot_kws={\"fontsize\":ANNOT_SIZE},\n",
    "    vmin=0,\n",
    "    vmax=100,\n",
    "    square=True,\n",
    "    cmap='coolwarm',\n",
    "    fmt='d',\n",
    "    ax=ax,\n",
    "    cbar_ax=cbar_ax,\n",
    ")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), fontsize=TICK_LABEL_SIZE, rotation=45, ha='right')\n",
    "ax.set_yticklabels([x.get_text().upper() for x in ax.get_yticklabels()], fontsize=TICK_LABEL_SIZE, rotation=0)\n",
    "cbar_ax.tick_params(labelsize=TICK_LABEL_SIZE)\n",
    "\n",
    "# figname = f\"figures_heatmap/{logical_transformation}_generalization.pdf\"\n",
    "# if os.path.exists(figname):\n",
    "#     os.remove(figname)\n",
    "# plt.savefig(figname, format='pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE_SIZE = 20\n",
    "TICK_LABEL_SIZE = 20\n",
    "ANNOT_SIZE = 20\n",
    "\n",
    "fig, axes = plt.subplots(1, len(probe_names), figsize=(19, 7), sharey=True)\n",
    "cbar_ax = fig.add_axes([1., .35, .01, .5])\n",
    "\n",
    "for i, probe in enumerate(probe_names):\n",
    "    ax = seaborn.heatmap(\n",
    "        pd.DataFrame(aurocs_avg[probe]).T,\n",
    "        annot=True,\n",
    "        annot_kws={\"fontsize\":ANNOT_SIZE},\n",
    "        vmin=0,\n",
    "        vmax=100,\n",
    "        square=True,\n",
    "        cmap='coolwarm',\n",
    "        fmt='d',\n",
    "        ax=axes[i],\n",
    "        cbar=(i==0),\n",
    "        cbar_ax=cbar_ax,\n",
    "    )\n",
    "    ax.set_title(probe.upper(), fontsize=TITLE_SIZE)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=TICK_LABEL_SIZE, rotation=45, ha='right')\n",
    "    if i == 0:\n",
    "        ax.set_yticklabels(ax.get_yticklabels(), fontsize=TICK_LABEL_SIZE)\n",
    "    else:\n",
    "        ax.tick_params(left=False)\n",
    "cbar_ax.tick_params(labelsize=TICK_LABEL_SIZE)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.01)\n",
    "\n",
    "figname = f\"figures_heatmap/{logical_transformation}_generalization_full.pdf\"\n",
    "if os.path.exists(figname):\n",
    "    os.remove(figname)\n",
    "plt.savefig(figname, format='pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalization to QA (MMLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, brier_score_loss\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "from probes import *\n",
    "from utils import *\n",
    "\n",
    "\n",
    "model_names_layer_indices = {\n",
    "    # \"Llama-2-7b-hf\": 12,\n",
    "    # \"Llama-2-7b-chat-hf\": 13,\n",
    "    # \"Llama-2-13b-hf\": 13,\n",
    "    # \"Llama-2-13b-chat-hf\": 13,\n",
    "    \"Meta-Llama-3.1-8B-hf\": 12,\n",
    "    # \"Meta-Llama-3.1-8B-Instruct-hf\": 13,\n",
    "    # \"Meta-Llama-3.1-70B-hf\": 33,\n",
    "    # \"Meta-Llama-3.1-70B-Instruct-hf\": 37,\n",
    "    # \"Mistral-Large-Instruct-2407\": 43,\n",
    "}\n",
    "\n",
    "prompt_option = \"no_prompt\"\n",
    "\n",
    "# topics = (\n",
    "#     \"mmlu_true_false\",\n",
    "#     \"mmlu_true_false_with_options\",\n",
    "#     \"mmlu_true_false_with_options_TTTTT\",\n",
    "#     \"mmlu_true_false_with_options_TTFFF\",\n",
    "# )\n",
    "# settings = ['no opt.', 'w/ opt.', 'TTTTT', 'TTFFF']\n",
    "\n",
    "topics = (\n",
    "    \"mmlu_true_false_mc\",\n",
    "    \"mmlu_true_false_mc_TTTTT\",\n",
    "    \"mmlu_true_false_mc_TTFFF\",\n",
    ")\n",
    "settings = ['0-shot', 'TTTTT', 'TTFFF']\n",
    "\n",
    "probe_names = ('lr', 'mlp', 'svm', 'mm')\n",
    "\n",
    "results = {}\n",
    "metrics = ['auroc', 'brier', 'ece']\n",
    "for m in metrics:\n",
    "    results[m] = []\n",
    "\n",
    "for seed in (0,1,2):\n",
    "    print(f\"seed={seed}\")\n",
    "    for m in results:\n",
    "        results[m].append({})\n",
    "    \n",
    "    for probe_name in probe_names:\n",
    "        print(f\"  probe={probe_name}\")\n",
    "        for m in results:\n",
    "            results[m][-1][probe_name] = {}\n",
    "        \n",
    "        for model_name, layer_index in model_names_layer_indices.items():\n",
    "            print(f\"    model={model_name}\")\n",
    "            for m in results:\n",
    "                results[m][-1][probe_name][model_name] = {}\n",
    "            \n",
    "            activations_dir = f\"activations_and_labels/{model_name}/{prompt_option}\"\n",
    "            probes_dir = f\"probes/{model_name}/seed={seed}\"\n",
    "            probe = joblib.load(os.path.join(probes_dir, f\"{probe_name}.joblib\"))\n",
    "            for topic in topics:\n",
    "                print(f\"      topic={topic}\")\n",
    "                \n",
    "                test_topic = topic\n",
    "                test_activations = np.load(f\"{activations_dir}/{test_topic}/acts_{layer_index}.npy\")\n",
    "                test_labels = pd.read_csv(f\"data/{test_topic}.csv\")['label']\n",
    "                test_labels = np.array(test_labels.tolist())\n",
    "                \n",
    "                test_pos_label_indices = np.where(test_labels==1)[0].tolist()\n",
    "                test_neg_label_indices = np.where(test_labels==0)[0].tolist()\n",
    "                num_test_pos_labels = np.count_nonzero(test_labels==1)\n",
    "                rng = np.random.RandomState(42)\n",
    "                test_neg_label_indices_chosen = rng.choice(test_neg_label_indices, num_test_pos_labels)\n",
    "                test_label_indices_chosen = np.concatenate([test_pos_label_indices, test_neg_label_indices_chosen])\n",
    "                test_activations = test_activations[test_label_indices_chosen]\n",
    "                test_labels = test_labels[test_label_indices_chosen]\n",
    "            \n",
    "                pos_label_probs = probe.predict_proba(test_activations)[:, 1]\n",
    "                auroc = roc_auc_score(test_labels, pos_label_probs)\n",
    "                results['auroc'][-1][probe_name][model_name][topic] = auroc\n",
    "                \n",
    "                brier =  brier_score_loss(test_labels, pos_label_probs)\n",
    "                results['brier'][-1][probe_name][model_name][topic] = brier\n",
    "                \n",
    "                prob_true, prob_pred = calibration_curve(test_labels, pos_label_probs, n_bins=10, strategy='quantile')\n",
    "                ece = calibration_error_expectation(prob_true, prob_pred)\n",
    "                results['ece'][-1][probe_name][model_name][topic] = ece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = {\n",
    "    \"probe\": [],\n",
    "    \"topic\": [],\n",
    "    \"auroc\": [],\n",
    "    \"brier\": [],\n",
    "    \"ece\":   [],\n",
    "}\n",
    "\n",
    "target_model = 'Meta-Llama-3.1-8B-hf'\n",
    "\n",
    "for index in range(len(results[metrics[0]])):\n",
    "    for probe_name in probe_names:\n",
    "        for topic in topics:\n",
    "            data_df['probe'].append(probe_name)\n",
    "            data_df['topic'].append(topic)\n",
    "            for m in metrics:\n",
    "                data_df[m].append(results[m][index][probe_name][target_model][topic])\n",
    "data_df = pd.DataFrame(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open-ended answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.set_theme('paper', 'white')\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=3, ncols=1, figsize=(9, 4), sharex=True, gridspec_kw={'hspace': 0.2}, height_ratios=(0.34, 0.33, 0.33))\n",
    "\n",
    "# PALETTE = [\"#e8ddcb\",\"#cdb380\",\"#036564\",\"#033649\",\"#031634\"]\n",
    "PALETTE = \"coolwarm\"\n",
    "\n",
    "seaborn.barplot(data_df, x='probe', y='auroc', hue='topic', order=('lr', 'mlp', 'mm', 'svm'), ax=ax1, errorbar=('se'), capsize=0.2, palette=PALETTE)\n",
    "seaborn.barplot(data_df, x='probe', y='ece',   hue='topic', order=('lr', 'mlp', 'mm', 'svm'), ax=ax2, errorbar=('se'), capsize=0.2, palette=PALETTE, legend=False)\n",
    "seaborn.barplot(data_df, x='probe', y='brier', hue='topic', order=('lr', 'mlp', 'mm', 'svm'), ax=ax3, errorbar=('se'), capsize=0.2, palette=PALETTE, legend=False)\n",
    "\n",
    "# ax1.axhline(0.5, ls='--', color='darkgray')\n",
    "ax1.set_ylim(0.5)\n",
    "\n",
    "ax2.set_ylim(0, 0.5)\n",
    "\n",
    "for t, l in zip(ax1.legend_.texts, settings):\n",
    "    t.set_text(l)\n",
    "ax1.legend_.set_title('')\n",
    "seaborn.move_legend(ax1, 'upper left', bbox_to_anchor=(0.12, 1.5), ncol=len(settings))\n",
    "\n",
    "ax1.set_ylabel(r\"AUROC$\\uparrow$\")\n",
    "ax2.set_ylabel(r\"ECE$\\downarrow$\")\n",
    "ax3.set_ylabel(r\"BS$\\downarrow$\")\n",
    "ax3.set_xlabel(\"Probe\")\n",
    "ax3.set_xticklabels([x.get_text().upper() for x in ax3.get_xticklabels()])\n",
    "\n",
    "ax1.tick_params(left=True)\n",
    "ax2.tick_params(left=True)\n",
    "ax3.tick_params(left=True)\n",
    "\n",
    "ax1.set_ylim(0.5, 0.8)\n",
    "ax1.set_yticks(np.linspace(0.5, 0.8, 4), np.linspace(0.5, 0.8, 4, dtype=np.float16))\n",
    "ax2.set_yticks(np.linspace(0, 0.4, 3), np.linspace(0, 0.4, 3, dtype=np.float16))\n",
    "ax3.set_ylim(0, 0.47)\n",
    "ax3.set_yticks(np.linspace(0, 0.4, 3), np.linspace(0, 0.4, 3, dtype=np.float16))\n",
    "ax3.axhline(0.25, ls='--', color='darkgray')\n",
    "\n",
    "FONTSIZE = 20\n",
    "plt.setp(ax1.get_legend().get_texts(), fontsize=FONTSIZE-4)\n",
    "\n",
    "ax1.tick_params(labelsize=FONTSIZE-6)\n",
    "ax2.tick_params(labelsize=FONTSIZE-6)\n",
    "ax3.tick_params(labelsize=FONTSIZE-6)\n",
    "\n",
    "ax3.set_xlabel(ax3.get_xlabel(), fontsize=FONTSIZE-6)\n",
    "\n",
    "ax1.set_ylabel(ax1.get_ylabel(), fontsize=FONTSIZE-6)\n",
    "ax2.set_ylabel(ax2.get_ylabel(), fontsize=FONTSIZE-6)\n",
    "ax3.set_ylabel(ax3.get_ylabel(), fontsize=FONTSIZE-6)\n",
    "\n",
    "for cont in ax1.containers:\n",
    "    ax1.bar_label(cont, fmt='%.2f', fontsize=10)\n",
    "for cont in ax2.containers:\n",
    "    ax2.bar_label(cont, fmt='%.2f', fontsize=10)\n",
    "for cont in ax3.containers:\n",
    "    ax3.bar_label(cont, fmt='%.2f', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"figures_qa/mmlu.pdf\", format='pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.set_theme('paper', 'white')\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=3, ncols=1, figsize=(9, 4), sharex=True, gridspec_kw={'hspace': 0.2}, height_ratios=(0.34, 0.33, 0.33))\n",
    "\n",
    "# PALETTE = [\"#e8ddcb\",\"#cdb380\",\"#036564\",\"#033649\",\"#031634\"]\n",
    "PALETTE = \"coolwarm\"\n",
    "palette = seaborn.color_palette(PALETTE)[2:]\n",
    "seaborn.barplot(data_df, x='probe', y='auroc', hue='topic', order=('lr', 'mlp', 'mm', 'svm'), ax=ax1, errorbar=('se'), capsize=0.2, palette=palette)\n",
    "seaborn.barplot(data_df, x='probe', y='ece',   hue='topic', order=('lr', 'mlp', 'mm', 'svm'), ax=ax2, errorbar=('se'), capsize=0.2, palette=palette, legend=False)\n",
    "seaborn.barplot(data_df, x='probe', y='brier', hue='topic', order=('lr', 'mlp', 'mm', 'svm'), ax=ax3, errorbar=('se'), capsize=0.2, palette=palette, legend=False)\n",
    "\n",
    "# ax1.axhline(0.5, ls='--', color='darkgray')\n",
    "ax1.set_ylim(0.5)\n",
    "\n",
    "ax2.set_ylim(0, 0.5)\n",
    "\n",
    "for t, l in zip(ax1.legend_.texts, settings):\n",
    "    t.set_text(l)\n",
    "ax1.legend_.set_title('')\n",
    "seaborn.move_legend(ax1, 'upper left', bbox_to_anchor=(0.23, 1.5), ncol=len(settings))\n",
    "\n",
    "ax1.set_ylabel(r\"AUROC$\\uparrow$\")\n",
    "ax2.set_ylabel(r\"ECE$\\downarrow$\")\n",
    "ax3.set_ylabel(r\"BS$\\downarrow$\")\n",
    "ax3.set_xlabel(\"Probe\")\n",
    "ax3.set_xticklabels([x.get_text().upper() for x in ax3.get_xticklabels()])\n",
    "\n",
    "ax1.tick_params(left=True)\n",
    "ax2.tick_params(left=True)\n",
    "ax3.tick_params(left=True)\n",
    "\n",
    "ax1.set_ylim(0.5, 0.8)\n",
    "ax1.set_yticks(np.linspace(0.5, 0.8, 4), np.linspace(0.5, 0.8, 4, dtype=np.float16))\n",
    "ax2.set_ylim(0, 0.55)\n",
    "ax2.set_yticks(np.linspace(0, 0.4, 3), np.linspace(0, 0.4, 3, dtype=np.float16))\n",
    "ax3.set_ylim(0, 0.55)\n",
    "ax3.set_yticks(np.linspace(0, 0.4, 3), np.linspace(0, 0.4, 3, dtype=np.float16))\n",
    "ax3.axhline(0.25, ls='--', color='darkgray')\n",
    "\n",
    "FONTSIZE = 20\n",
    "plt.setp(ax1.get_legend().get_texts(), fontsize=FONTSIZE-4)\n",
    "\n",
    "ax1.tick_params(labelsize=FONTSIZE-6)\n",
    "ax2.tick_params(labelsize=FONTSIZE-6)\n",
    "ax3.tick_params(labelsize=FONTSIZE-6)\n",
    "\n",
    "ax3.set_xlabel(ax3.get_xlabel(), fontsize=FONTSIZE-6)\n",
    "\n",
    "ax1.set_ylabel(ax1.get_ylabel(), fontsize=FONTSIZE-6)\n",
    "ax2.set_ylabel(ax2.get_ylabel(), fontsize=FONTSIZE-6)\n",
    "ax3.set_ylabel(ax3.get_ylabel(), fontsize=FONTSIZE-6)\n",
    "\n",
    "for cont in ax1.containers:\n",
    "    ax1.bar_label(cont, fmt='%.2f', fontsize=10)\n",
    "for cont in ax2.containers:\n",
    "    ax2.bar_label(cont, fmt='%.2f', fontsize=10)\n",
    "for cont in ax3.containers:\n",
    "    ax3.bar_label(cont, fmt='%.2f', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"figures_qa/mmlu_mc.pdf\", format='pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalization to QA (In-context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, brier_score_loss\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from itertools import chain\n",
    "\n",
    "from probes import *\n",
    "from utils import *\n",
    "\n",
    "\n",
    "model_names_layer_indices = {\n",
    "    # \"Llama-2-7b-hf\": 12,\n",
    "    # \"Llama-2-7b-chat-hf\": 13,\n",
    "    # \"Llama-2-13b-hf\": 13,\n",
    "    # \"Llama-2-13b-chat-hf\": 13,\n",
    "    \"Meta-Llama-3.1-8B-hf\": 12,\n",
    "    # \"Meta-Llama-3.1-8B-Instruct-hf\": 13,\n",
    "    # \"Meta-Llama-3.1-70B-hf\": 33,\n",
    "    # \"Meta-Llama-3.1-70B-Instruct-hf\": 18,\n",
    "    # \"Mistral-Large-Instruct-2407\": 43,\n",
    "}\n",
    "\n",
    "prompt_option = \"no_prompt\"\n",
    "\n",
    "topics = (\n",
    "    (\n",
    "        \"sciq_true_false_mc\",\n",
    "        \"sciq_true_false_mc_TTT\",\n",
    "        \"sciq_true_false_mc_TTF\",\n",
    "        \"sciq_true_false_mc_FFT\",\n",
    "    ),\n",
    "    (\n",
    "        \"boolq_true_false\",\n",
    "        \"boolq_true_false_with_options\",\n",
    "        \"boolq_true_false_with_options_T\",\n",
    "        \"boolq_true_false_with_options_F\",\n",
    "    ),\n",
    "    (\n",
    "        \"xsum_true_false\",\n",
    "        \"xsum_true_false_T\",\n",
    "        \"xsum_true_false_TT\",\n",
    "        \"xsum_true_false_TTT\",\n",
    "    ),\n",
    ")\n",
    "settings = (\n",
    "    ('0-shot', 'TTT', 'TTF', 'FFT'),\n",
    "    ('no opt.', 'w/ opt.', 'T', 'F'),\n",
    "    ('0-shot', 'T', 'TT', 'TTT'),\n",
    ")\n",
    "\n",
    "probe_names = ('lr', 'mlp', 'svm', 'mm')\n",
    "\n",
    "results = {}\n",
    "metrics = ['auroc', 'brier', 'ece']\n",
    "for m in metrics:\n",
    "    results[m] = []\n",
    "\n",
    "for seed in (0,1,2):\n",
    "    print(f\"seed={seed}\")\n",
    "    for m in results:\n",
    "        results[m].append({})\n",
    "    \n",
    "    for probe_name in probe_names:\n",
    "        print(f\"  probe={probe_name}\")\n",
    "        for m in results:\n",
    "            results[m][-1][probe_name] = {}\n",
    "        \n",
    "        for model_name, layer_index in model_names_layer_indices.items():\n",
    "            print(f\"    model={model_name}\")\n",
    "            for m in results:\n",
    "                results[m][-1][probe_name][model_name] = {}\n",
    "            \n",
    "            activations_dir = f\"activations_and_labels/{model_name}/{prompt_option}\"\n",
    "            probes_dir = f\"probes/{model_name}/seed={seed}\"\n",
    "            probe = joblib.load(os.path.join(probes_dir, f\"{probe_name}.joblib\"))\n",
    "            for topic in chain(*topics):\n",
    "                print(f\"      topic={topic}\")\n",
    "                \n",
    "                test_topic = topic\n",
    "                test_activations = np.load(f\"{activations_dir}/{test_topic}/acts_{layer_index}.npy\")\n",
    "                test_labels = pd.read_csv(f\"data/{test_topic}.csv\")['label']\n",
    "                test_labels = np.array(test_labels.tolist())\n",
    "                \n",
    "                test_pos_label_indices = np.where(test_labels==1)[0].tolist()\n",
    "                test_neg_label_indices = np.where(test_labels==0)[0].tolist()\n",
    "                num_test_pos_labels = np.count_nonzero(test_labels==1)\n",
    "                rng = np.random.RandomState(42)\n",
    "                test_neg_label_indices_chosen = rng.choice(test_neg_label_indices, num_test_pos_labels)\n",
    "                test_label_indices_chosen = np.concatenate([test_pos_label_indices, test_neg_label_indices_chosen])\n",
    "                test_activations = test_activations[test_label_indices_chosen]\n",
    "                test_labels = test_labels[test_label_indices_chosen]\n",
    "            \n",
    "                pos_label_probs = probe.predict_proba(test_activations)[:, 1]\n",
    "                auroc = roc_auc_score(test_labels, pos_label_probs)\n",
    "                results['auroc'][-1][probe_name][model_name][topic] = auroc\n",
    "                \n",
    "                brier =  brier_score_loss(test_labels, pos_label_probs)\n",
    "                results['brier'][-1][probe_name][model_name][topic] = brier\n",
    "                \n",
    "                prob_true, prob_pred = calibration_curve(test_labels, pos_label_probs, n_bins=10, strategy='quantile')\n",
    "                ece = calibration_error_expectation(prob_true, prob_pred)\n",
    "                results['ece'][-1][probe_name][model_name][topic] = ece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = {\n",
    "    \"probe\": [],\n",
    "    \"topic\": [],\n",
    "    \"auroc\": [],\n",
    "    \"brier\": [],\n",
    "    \"ece\":   [],\n",
    "}\n",
    "\n",
    "target_model = 'Meta-Llama-3.1-8B-hf'\n",
    "# target_model = 'Meta-Llama-3.1-70B-Instruct-hf'\n",
    "\n",
    "for index in range(len(results[metrics[0]])):\n",
    "    for probe_name in probe_names:\n",
    "        for topic in chain(*topics):\n",
    "            data_df['probe'].append(probe_name)\n",
    "            data_df['topic'].append(topic)\n",
    "            for m in metrics:\n",
    "                data_df[m].append(results[m][index][probe_name][target_model][topic])\n",
    "data_df = pd.DataFrame(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deprecated\n",
    "\n",
    "seaborn.set_theme('paper', 'whitegrid')\n",
    "\n",
    "tasks = (\"SciQ\", \"BoolQ\", \"XSum\")\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(13, 3), sharey='row', gridspec_kw={'hspace': 0, 'wspace': 0.01}, height_ratios=(0.6, 0.4))\n",
    "\n",
    "# PALETTE = [\"#e8ddcb\",\"#cdb380\",\"#036564\",\"#033649\",\"#031634\"]\n",
    "PALETTE = 'coolwarm'\n",
    "for i in range(len(topics)):\n",
    "    topic_df = data_df.loc[data_df['topic'].isin(topics[i])]\n",
    "    if i == 2:\n",
    "        palette = seaborn.color_palette(PALETTE)\n",
    "        palette = palette[0:1] + palette[-3:]\n",
    "    else:\n",
    "        palette = PALETTE\n",
    "    seaborn.barplot(topic_df, x='probe', y='auroc', hue='topic', order=('lr', 'mlp', 'mm', 'svm'), ax=axes[0][i], errorbar=('se'), capsize=0.2, palette=palette, legend=False)\n",
    "    seaborn.barplot(topic_df, x='probe', y='ece', hue='topic', order=('lr', 'mlp', 'mm', 'svm'), ax=axes[1][i], errorbar=('se'), capsize=0.2, palette=palette)\n",
    "\n",
    "axes[0][0].tick_params(left=True)\n",
    "axes[1][0].tick_params(left=True)\n",
    "\n",
    "for ax, setting in zip(axes[1], settings):\n",
    "    for t, l in zip(ax.legend_.texts, setting):\n",
    "        t.set_text(l)\n",
    "    ax.legend_.set_title('')\n",
    "    ax.legend_.set_ncols(len(setting))\n",
    "    seaborn.move_legend(ax, 'upper left', bbox_to_anchor=(0, -0.5))\n",
    "\n",
    "for ax in axes[1]:\n",
    "    ax.set_ylim(0, 0.44)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "FONTSIZE = 16\n",
    "axes[0][0].set_ylabel(r\"AUROC$\\uparrow$\", fontsize=FONTSIZE-2)\n",
    "axes[1][0].set_ylabel(r\"ECE$\\downarrow$\", fontsize=FONTSIZE-2)\n",
    "\n",
    "axes[0][0].tick_params(labelsize=FONTSIZE-2)\n",
    "axes[1][0].tick_params(labelsize=FONTSIZE-2)\n",
    "\n",
    "for ax, task in zip(axes[0], tasks):\n",
    "    ax.set_yticks(np.linspace(0,1,6), np.linspace(0,1,6, dtype=np.float16))\n",
    "    ax.set_title(task, fontsize=FONTSIZE)\n",
    "    ax.axhline(0.5, ls='--', color='darkgray')\n",
    "\n",
    "for ax in axes[1]:\n",
    "    plt.setp(ax.get_legend().get_texts(), fontsize=FONTSIZE-2)\n",
    "    ax.tick_params(labelsize=FONTSIZE-2)\n",
    "    ax.set_xlabel(\"Probe\", fontsize=FONTSIZE-2)\n",
    "    ax.set_xticklabels([x.get_text().upper() for x in ax.get_xticklabels()])\n",
    "    ax.set_yticks(np.linspace(0.1, 0.4, 4), np.linspace(0.1, 0.4, 4, dtype=np.float16))\n",
    "# ax2.set_xlabel(ax2.get_xlabel(), fontsize=FONTSIZE)\n",
    "# ax1.set_ylabel(ax1.get_ylabel(), fontsize=FONTSIZE)\n",
    "# ax2.set_ylabel(ax2.get_ylabel(), fontsize=FONTSIZE)\n",
    "\n",
    "# for axes_row in axes:\n",
    "#     for ax in axes_row:\n",
    "#         for cont in ax.containers:\n",
    "#             ax.bar_label(cont, fmt='%.2f', fontsize=5)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"figures_qa/contextual_qa.pdf\", format='pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.set_theme('paper', 'whitegrid')\n",
    "\n",
    "tasks = (\"SciQ\", \"BoolQ\", \"XSum\")\n",
    "settings = (\n",
    "    ('0-shot', 'TTT', 'TTF', 'FFT'),\n",
    "    ('no opt.', 'w/ opt.', 'T', 'F'),\n",
    "    ('0-shot', 'T', 'TT', 'TTT'),\n",
    ")\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(13, 3), sharex=True, sharey='row', gridspec_kw={'hspace': 0.2, 'wspace': 0.01}, height_ratios=(0.34, 0.33, 0.33))\n",
    "\n",
    "PALETTE = 'coolwarm'\n",
    "for i in range(len(topics)):\n",
    "    topic_df = data_df.loc[data_df['topic'].isin(topics[i])]\n",
    "    if i == 2:\n",
    "        palette = seaborn.color_palette(PALETTE)\n",
    "        palette = palette[1:2] + palette[-3:]\n",
    "    else:\n",
    "        palette = seaborn.color_palette(PALETTE)[1:]\n",
    "    seaborn.barplot(topic_df, x='probe', y='auroc', hue='topic', order=('lr', 'mlp', 'mm', 'svm'), ax=axes[0][i], errorbar=('se'), capsize=0.2, palette=palette, legend=False)\n",
    "    seaborn.barplot(topic_df, x='probe', y='ece',   hue='topic', order=('lr', 'mlp', 'mm', 'svm'), ax=axes[1][i], errorbar=('se'), capsize=0.2, palette=palette, legend=False)\n",
    "    seaborn.barplot(topic_df, x='probe', y='brier', hue='topic', order=('lr', 'mlp', 'mm', 'svm'), ax=axes[2][i], errorbar=('se'), capsize=0.2, palette=palette)\n",
    "\n",
    "axes[0][0].tick_params(left=True)\n",
    "axes[1][0].tick_params(left=True)\n",
    "axes[2][0].tick_params(left=True)\n",
    "\n",
    "for ax, setting in zip(axes[2], settings):\n",
    "    for t, l in zip(ax.legend_.texts, setting):\n",
    "        t.set_text(l)\n",
    "    ax.legend_.set_title('')\n",
    "seaborn.move_legend(axes[2][0], 'upper left', bbox_to_anchor=(0.045, -0.6), ncol=len(setting), columnspacing=0.1)\n",
    "seaborn.move_legend(axes[2][1], 'upper left', bbox_to_anchor=(0.05, -0.6), ncol=len(setting), columnspacing=0.1)\n",
    "seaborn.move_legend(axes[2][2], 'upper left', bbox_to_anchor=(0.07, -0.6), ncol=len(setting), columnspacing=0.1)\n",
    "\n",
    "for ax in axes[1]:\n",
    "    ax.set_ylim(0, 0.44)\n",
    "\n",
    "FONTSIZE = 16\n",
    "axes[0][0].set_ylabel(r\"AUROC$\\uparrow$\", fontsize=FONTSIZE-4)\n",
    "axes[1][0].set_ylabel(r\"ECE$\\downarrow$\", fontsize=FONTSIZE-4)\n",
    "axes[2][0].set_ylabel(r\"BS$\\downarrow$\", fontsize=FONTSIZE-4)\n",
    "\n",
    "axes[0][0].tick_params(labelsize=FONTSIZE-6)\n",
    "\n",
    "for ax, task in zip(axes[0], tasks):\n",
    "    ax.set_ylim(0.5, 1.0)\n",
    "    ax.set_yticks(np.linspace(0.5,1,6), np.linspace(0.5,1,6, dtype=np.float16))\n",
    "    ax.set_title(task, fontsize=FONTSIZE-4)\n",
    "    # ax.axhline(0.5, ls='--', color='darkgray')\n",
    "\n",
    "for ax in axes[1]:\n",
    "    ax.tick_params(labelsize=FONTSIZE-6, top=False, bottom=False, which='both')\n",
    "    ax.set_yticks(np.linspace(0., 0.4, 5), np.linspace(0., 0.4, 5, dtype=np.float16))\n",
    "\n",
    "for ax in axes[2]:\n",
    "    plt.setp(ax.get_legend().get_texts(), fontsize=FONTSIZE-4)\n",
    "    ax.tick_params(labelsize=FONTSIZE-6, top=False, bottom=False, which='both')\n",
    "    ax.set_xlabel(\"Probe\", fontsize=FONTSIZE-6)\n",
    "    ax.set_xticklabels([x.get_text().upper() for x in ax.get_xticklabels()])\n",
    "    ax.set_yticks(np.linspace(0., 0.4, 5), np.linspace(0., 0.4, 5, dtype=np.float16))\n",
    "    ax.axhline(0.25, ls='--', color='darkgray')\n",
    "\n",
    "# for axes_row in axes:\n",
    "#     for ax in axes_row:\n",
    "#         for cont in ax.containers:\n",
    "#             ax.bar_label(cont, fmt='%.2f', fontsize=5)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"figures_qa/contextual_qa.pdf\", format='pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1.axhline(0.5, ls='--', color='darkgray')\n",
    "# ax2.axhline(0.25, ls='--', color='darkgray')\n",
    "\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "for t, l in zip(ax1.legend_.texts, settings):\n",
    "    t.set_text(l)\n",
    "ax1.legend_.set_title('')\n",
    "seaborn.move_legend(ax1, 'lower right')\n",
    "ax2.legend_.remove()\n",
    "\n",
    "ax1.set_ylabel(r\"AUROC$\\uparrow$\")\n",
    "ax2.set_ylabel(r\"ECE$\\downarrow$\")\n",
    "ax2.set_xlabel(\"Probe\")\n",
    "ax2.set_xticklabels([x.get_text().upper() for x in ax2.get_xticklabels()])\n",
    "ax1.tick_params(left=True)\n",
    "ax2.tick_params(left=True)\n",
    "\n",
    "# ax1.set_ylim(0, 1.1)\n",
    "\n",
    "\n",
    "ax2.set_yticks(np.linspace(0.1, 0.3, 3), np.linspace(0.1, 0.3, 3, dtype=np.float16))\n",
    "\n",
    "# ax2.set_yticks((0.1, 0.2, 0.3, 0.4), (0.1, 0.2, 0.3, 0.4)) # sciq\n",
    "\n",
    "FONTSIZE = 20\n",
    "plt.setp(ax1.get_legend().get_texts(), fontsize=FONTSIZE-2)\n",
    "ax2.tick_params(labelsize=FONTSIZE-2)\n",
    "ax1.tick_params(labelsize=FONTSIZE-2)\n",
    "ax2.set_xlabel(ax2.get_xlabel(), fontsize=FONTSIZE)\n",
    "ax1.set_ylabel(ax1.get_ylabel(), fontsize=FONTSIZE)\n",
    "ax2.set_ylabel(ax2.get_ylabel(), fontsize=FONTSIZE)\n",
    "\n",
    "for cont in ax1.containers:\n",
    "    ax1.bar_label(cont, fmt='%.2f', fontsize=FONTSIZE-8)\n",
    "for cont in ax2.containers:\n",
    "    ax2.bar_label(cont, fmt='%.2f', fontsize=FONTSIZE-8)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"figures_qa/xsum.pdf\", format='pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TriviaQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, brier_score_loss\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "from probes import *\n",
    "from utils import *\n",
    "\n",
    "\n",
    "model_names_layer_indices = {\n",
    "    # \"Llama-2-7b-hf\": 12,\n",
    "    # \"Llama-2-7b-chat-hf\": 13,\n",
    "    # \"Llama-2-13b-hf\": 13,\n",
    "    # \"Llama-2-13b-chat-hf\": 13,\n",
    "    \"Meta-Llama-3.1-8B-hf\": 12,\n",
    "    # \"Meta-Llama-3.1-8B-Instruct-hf\": 13,\n",
    "    # \"Meta-Llama-3.1-70B-hf\": 33,\n",
    "    # \"Meta-Llama-3.1-70B-Instruct-hf\": 37,\n",
    "    # \"Mistral-Large-Instruct-2407\": 43,\n",
    "}\n",
    "\n",
    "prompt_option = \"no_prompt\"\n",
    "\n",
    "topics = (\n",
    "    \"triviaqa_true_false_Meta-Llama-3.1-8B-hf-shots=5\",\n",
    "    \"triviaqa_true_false_Meta-Llama-3.1-8B-hf-shots=20\",\n",
    ")\n",
    "settings = ['5-shot', '20-shot']\n",
    "\n",
    "probe_names = ('lr', 'mlp', 'svm', 'mm')\n",
    "\n",
    "results = {}\n",
    "metrics = ['auroc', 'brier', 'ece']\n",
    "for m in metrics:\n",
    "    results[m] = []\n",
    "\n",
    "for seed in (0,1,2):\n",
    "    print(f\"seed={seed}\")\n",
    "    for m in results:\n",
    "        results[m].append({})\n",
    "    \n",
    "    for probe_name in probe_names:\n",
    "        print(f\"  probe={probe_name}\")\n",
    "        for m in results:\n",
    "            results[m][-1][probe_name] = {}\n",
    "        \n",
    "        for model_name, layer_index in model_names_layer_indices.items():\n",
    "            print(f\"    model={model_name}\")\n",
    "            for m in results:\n",
    "                results[m][-1][probe_name][model_name] = {}\n",
    "            \n",
    "            activations_dir = f\"activations_and_labels/{model_name}/{prompt_option}\"\n",
    "            probes_dir = f\"probes/{model_name}/seed={seed}\"\n",
    "            probe = joblib.load(os.path.join(probes_dir, f\"{probe_name}.joblib\"))\n",
    "            for topic in topics:\n",
    "                print(f\"      topic={topic}\")\n",
    "                \n",
    "                test_topic = topic\n",
    "                test_activations = np.load(f\"{activations_dir}/{test_topic}/acts_{layer_index}.npy\")\n",
    "                test_labels = pd.read_csv(f\"data/{test_topic}.csv\")['label']\n",
    "                test_labels = np.array(test_labels.tolist())\n",
    "                \n",
    "                # test_pos_label_indices = np.where(test_labels==1)[0].tolist()\n",
    "                # test_neg_label_indices = np.where(test_labels==0)[0].tolist()\n",
    "                # num_test_pos_labels = np.count_nonzero(test_labels==1)\n",
    "                # rng = np.random.RandomState(42)\n",
    "                # test_neg_label_indices_chosen = rng.choice(test_neg_label_indices, num_test_pos_labels)\n",
    "                # test_label_indices_chosen = np.concatenate([test_pos_label_indices, test_neg_label_indices_chosen])\n",
    "                # test_activations = test_activations[test_label_indices_chosen]\n",
    "                # test_labels = test_labels[test_label_indices_chosen]\n",
    "            \n",
    "                pos_label_probs = probe.predict_proba(test_activations)[:, 1]\n",
    "                auroc = roc_auc_score(test_labels, pos_label_probs)\n",
    "                results['auroc'][-1][probe_name][model_name][topic] = auroc\n",
    "                \n",
    "                brier =  brier_score_loss(test_labels, pos_label_probs)\n",
    "                results['brier'][-1][probe_name][model_name][topic] = brier\n",
    "                \n",
    "                prob_true, prob_pred = calibration_curve(test_labels, pos_label_probs, n_bins=10, strategy='quantile')\n",
    "                ece = calibration_error_expectation(prob_true, prob_pred)\n",
    "                results['ece'][-1][probe_name][model_name][topic] = ece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = {\n",
    "    \"probe\": [],\n",
    "    \"topic\": [],\n",
    "    \"auroc\": [],\n",
    "    \"brier\": [],\n",
    "    \"ece\":   [],\n",
    "}\n",
    "\n",
    "target_model = 'Meta-Llama-3.1-8B-hf'\n",
    "\n",
    "for index in range(len(results[metrics[0]])):\n",
    "    for probe_name in probe_names:\n",
    "        for topic in topics:\n",
    "            data_df['probe'].append(probe_name)\n",
    "            data_df['topic'].append(topic)\n",
    "            for m in metrics:\n",
    "                data_df[m].append(results[m][index][probe_name][target_model][topic])\n",
    "data_df = pd.DataFrame(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.set_theme('paper', 'white')\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=3, ncols=1, figsize=(9, 4), sharex=True, gridspec_kw={'hspace': 0.2}, height_ratios=(0.34, 0.33, 0.33))\n",
    "\n",
    "# PALETTE = [\"#e8ddcb\",\"#cdb380\",\"#036564\",\"#033649\",\"#031634\"]\n",
    "PALETTE = \"coolwarm\"\n",
    "\n",
    "seaborn.barplot(data_df, x='probe', y='auroc', hue='topic', order=('lr', 'mlp', 'mm', 'svm'), ax=ax1, errorbar=('se'), capsize=0.2, palette=PALETTE)\n",
    "seaborn.barplot(data_df, x='probe', y='ece',   hue='topic', order=('lr', 'mlp', 'mm', 'svm'), ax=ax2, errorbar=('se'), capsize=0.2, palette=PALETTE, legend=False)\n",
    "seaborn.barplot(data_df, x='probe', y='brier', hue='topic', order=('lr', 'mlp', 'mm', 'svm'), ax=ax3, errorbar=('se'), capsize=0.2, palette=PALETTE, legend=False)\n",
    "\n",
    "# ax1.axhline(0.5, ls='--', color='darkgray')\n",
    "ax1.set_ylim(0.5)\n",
    "\n",
    "ax2.set_ylim(0, 0.5)\n",
    "\n",
    "for t, l in zip(ax1.legend_.texts, settings):\n",
    "    t.set_text(l)\n",
    "ax1.legend_.set_title('')\n",
    "seaborn.move_legend(ax1, 'upper left', bbox_to_anchor=(0.31, 1.5), ncol=len(settings))\n",
    "\n",
    "ax1.set_ylabel(r\"AUROC$\\uparrow$\")\n",
    "ax2.set_ylabel(r\"ECE$\\downarrow$\")\n",
    "ax3.set_ylabel(r\"BS$\\downarrow$\")\n",
    "ax3.set_xlabel(\"Probe\")\n",
    "ax3.set_xticklabels([x.get_text().upper() for x in ax3.get_xticklabels()])\n",
    "\n",
    "ax1.tick_params(left=True)\n",
    "ax2.tick_params(left=True)\n",
    "ax3.tick_params(left=True)\n",
    "\n",
    "ax1.set_ylim(0.5, 0.82)\n",
    "ax1.set_yticks(np.linspace(0.5, 0.8, 4), np.linspace(0.5, 0.8, 4, dtype=np.float16))\n",
    "ax2.set_yticks(np.linspace(0, 0.4, 3), np.linspace(0, 0.4, 3, dtype=np.float16))\n",
    "ax3.set_ylim(0, 0.47)\n",
    "ax3.set_yticks(np.linspace(0, 0.4, 3), np.linspace(0, 0.4, 3, dtype=np.float16))\n",
    "ax3.axhline(0.25, ls='--', color='darkgray')\n",
    "\n",
    "FONTSIZE = 20\n",
    "plt.setp(ax1.get_legend().get_texts(), fontsize=FONTSIZE-4)\n",
    "\n",
    "ax1.tick_params(labelsize=FONTSIZE-6)\n",
    "ax2.tick_params(labelsize=FONTSIZE-6)\n",
    "ax3.tick_params(labelsize=FONTSIZE-6)\n",
    "\n",
    "ax3.set_xlabel(ax3.get_xlabel(), fontsize=FONTSIZE-6)\n",
    "\n",
    "ax1.set_ylabel(ax1.get_ylabel(), fontsize=FONTSIZE-6)\n",
    "ax2.set_ylabel(ax2.get_ylabel(), fontsize=FONTSIZE-6)\n",
    "ax3.set_ylabel(ax3.get_ylabel(), fontsize=FONTSIZE-6)\n",
    "\n",
    "for cont in ax1.containers:\n",
    "    ax1.bar_label(cont, fmt='%.3f', fontsize=10)\n",
    "for cont in ax2.containers:\n",
    "    ax2.bar_label(cont, fmt='%.3f', fontsize=10)\n",
    "for cont in ax3.containers:\n",
    "    ax3.bar_label(cont, fmt='%.3f', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"figures_qa/triviaqa.pdf\", format='pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TriviaQA Selective QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "from probes import *\n",
    "from utils import *\n",
    "\n",
    "\n",
    "prompt_option = \"no_prompt\"\n",
    "\n",
    "model_names_layer_indices = {\n",
    "    # \"Llama-2-7b-hf\": 12,\n",
    "    # \"Llama-2-7b-chat-hf\": 13,\n",
    "    \"Llama-2-13b-hf\": 13,\n",
    "    # \"Llama-2-13b-chat-hf\": 13,\n",
    "    \"Meta-Llama-3.1-8B-hf\": 12,\n",
    "    # \"Meta-Llama-3.1-8B-Instruct-hf\": 13,\n",
    "    # \"Meta-Llama-3.1-70B-hf\": 33,\n",
    "    # \"Meta-Llama-3.1-70B-Instruct-hf\": 37,\n",
    "    # \"Mistral-Large-Instruct-2407\": 37,\n",
    "}\n",
    "\n",
    "vanilla_accs = {\n",
    "    \"Llama-2-13b-hf\": 0.5824,\n",
    "    \"Meta-Llama-3.1-8B-hf\": 0.55168,\n",
    "}\n",
    "\n",
    "disp = {\n",
    "    'Method': [], 'Exact Match': [], 'Model': []\n",
    "}\n",
    "for model_name, layer_index in model_names_layer_indices.items():\n",
    "    print(f\"model={model_name}\")\n",
    "    activations_dir = f\"activations_and_labels/{model_name}/{prompt_option}\"\n",
    "\n",
    "    test_topic = f\"triviaqa_true_false_{model_name}\"\n",
    "    test_activations = np.load(f\"{activations_dir}/{test_topic}/acts_{layer_index}.npy\")\n",
    "    test_labels = pd.read_csv(f\"data/{test_topic}.csv\")['label']\n",
    "    test_labels = np.array(test_labels.tolist())\n",
    "\n",
    "    probe_names = ('lr', 'mlp', 'svm', 'mm')\n",
    "\n",
    "    disp['Method'].append(\"Vanilla\")\n",
    "    disp['Exact Match'].append(vanilla_accs[model_name])\n",
    "    disp['Model'].append(model_name)\n",
    "\n",
    "    for seed in (0,1,2):\n",
    "        print(f\"  seed={seed}\")\n",
    "        probes_dir = f\"probes/{model_name}/seed={seed}\"\n",
    "        lr = joblib.load(os.path.join(probes_dir, \"lr.joblib\"))\n",
    "        mlp = joblib.load(os.path.join(probes_dir, \"mlp.joblib\"))\n",
    "        svm = joblib.load(os.path.join(probes_dir, \"svm.joblib\"))\n",
    "        mm = joblib.load(os.path.join(probes_dir, \"mm.joblib\"))\n",
    "\n",
    "        for probe_name in probe_names:\n",
    "            print(f\"    probe={probe_name}\")\n",
    "            probe = locals()[probe_name]\n",
    "            pos_probs = probe.predict_proba(test_activations)[:,1]\n",
    "            selected_answers = test_labels[pos_probs>0.5]\n",
    "            cacc = np.sum(selected_answers) / len(selected_answers)\n",
    "            disp['Method'].append(probe_name.upper())\n",
    "            disp['Exact Match'].append(cacc)\n",
    "            disp['Model'].append(model_name.replace(\"-hf\",\"\").replace(\"Meta-\",\"\").replace('b','B').replace(\"-chat\",\"-Chat\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.set_theme('paper', 'whitegrid')\n",
    "\n",
    "TICK_LABEL_SIZE = 16\n",
    "plt.figure(figsize=(6,3.5))\n",
    "ax = seaborn.barplot(disp, x='Method', y='Exact Match', hue='Model', legend=True, width=0.6, palette=['b', 'g'], errorbar=('sd'), capsize=0.2)\n",
    "# ax.set_xticklabels(ax.get_xticklabels(), fontsize=TICK_LABEL_SIZE)\n",
    "# ax.set_yticklabels(ax.get_yticklabels(), fontsize=TICK_LABEL_SIZE)\n",
    "ax.set_xlabel(ax.get_xlabel(), fontsize=TICK_LABEL_SIZE)\n",
    "ax.set_ylabel(\"EM\", fontsize=TICK_LABEL_SIZE)\n",
    "ax.tick_params(left=True, labelsize=TICK_LABEL_SIZE)\n",
    "# ax.set_yticks(np.linspace(0,0.9,4), np.linspace(0,0.9,4))\n",
    "ax.set_ylim(0, .85)\n",
    "# for cont in ax.containers:\n",
    "#     ax.bar_label(cont, fmt='%.3f', fontsize=TICK_LABEL_SIZE)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures_selective_qa/selective_qa.pdf\", format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Framework figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model\n",
    "plt.rc('text')\n",
    "\n",
    "pts = np.loadtxt('linpts.txt')\n",
    "X = pts[:,:2]\n",
    "Y = pts[:,2].astype('int')\n",
    "\n",
    "# Fit the data to a logistic regression model.\n",
    "clf = sklearn.linear_model.LogisticRegression()\n",
    "clf.fit(X, Y)\n",
    "\n",
    "# Retrieve the model parameters.\n",
    "b = clf.intercept_[0]\n",
    "w1, w2 = clf.coef_.T\n",
    "# Calculate the intercept and gradient of the decision boundary.\n",
    "c = -b/w2\n",
    "m = -w1/w2\n",
    "\n",
    "# Plot the data and the classification with the decision boundary.\n",
    "xmin, xmax = -0.6, 1.4\n",
    "ymin, ymax = -0.8, 2.2\n",
    "xd = np.array([xmin, xmax])\n",
    "yd = m*xd + c\n",
    "plt.plot(xd, yd, 'k', lw=1, ls='--')\n",
    "plt.fill_between(xd, yd, ymin, color='tab:blue', alpha=0.2)\n",
    "plt.fill_between(xd, yd, ymax, color='tab:orange', alpha=0.2)\n",
    "\n",
    "plt.scatter(*X[Y==0].T, s=8, alpha=0.5)\n",
    "plt.scatter(*X[Y==1].T, s=8, alpha=0.5)\n",
    "plt.xlim(xmin, xmax)\n",
    "plt.ylim(ymin, ymax)\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "plt.text(xmin+0.3, ymin+0.3, 'False', fontsize=40)\n",
    "plt.text(xmax-0.6, ymax-0.5, 'True', fontsize=40)\n",
    "\n",
    "plt.savefig('hyperplane.pdf', dpi=400, bbox_inches='tight')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reptda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
